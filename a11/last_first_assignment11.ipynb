{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 11 \n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Download last_first_assignment11.ipynb. Fill in the code where indicated to complete the assignment. Feel free to add more cells than provided to try things out, and check what your variables look like, to see if you got the right results. Just make sure you have done what is asked for that question and that you don't delete any code we provide you with. \n",
    "\n",
    "2. Rename this `last_first_assignment11.ipynb` file replacing `last` and `first` with your name. Make sure all the outputs are there (run each cell) and then export as `last_first_assignment11.py` as well.\n",
    "\n",
    "3. Submit both these files to Quercus.\n",
    "\n",
    "## Questions and Support\n",
    "1. Please ask class content questions on the class GitHub page: \n",
    "https://github.com/BME1478H/Fall2020class/ Expect a processing time of 1d for us to respond. As such, we cannot guarantee we can address your questions and work through all the troubleshooting in time if you ask them the night before or the day of the assignment deadline. Please plan accordingly.\n",
    "\n",
    "___\n",
    "In this assignment, we will go through a start-to-finish analysis of a dataset which involves exploring the data, testing some hypothesis and making predictions based on patterns in our data. We have created a modified gapminder dataset with some of the same columns we've seen before, and some new ones. \n",
    "\n",
    "To start the assignment, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/BME1478H/Winter2020class/master/data/final-assignment-gapminder.csv'\n",
    "world_data = pd.read_csv(url)\n",
    "\n",
    "# take a look at the data\n",
    "world_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the data (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are some new columns we haven't seen before. Here is some more information about them:\n",
    "\n",
    "- \"bp_men\" and \"bp_women\" are the average blood pressure in mmhg for men and women, respectively\n",
    "- \"sugar_intake_daily\" is the average sugar intake in grams per person per day\n",
    "\n",
    "To facilitate exploration of the new columns and how they may relate to `life_expectancy`, we will focus on the data from a single year.\n",
    "___\n",
    "\n",
    "a. Create a subset of `world_data` called `wd_2005` keeping only rows where the year is 2005. **(0.5 marks)**\n",
    "\n",
    "b. Create a pairplot of `wd_2005`, but instead of plotting every pair-wise comparison, we only want to plot the `life_expectancy` column (on the y-axis) against some of the columns on the x-axis (`['income', 'children_per_woman', 'sugar_intake_daily', 'bp_men', 'bp_women']`). To do this, read the docstring of the `sns.pairplot()` function to figure out how you can control which x and y-variables will be plotted. **(0.5 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_2005 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your plot here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hint: We create a pairplot typically using `sns.pairplot(df_name)`. \n",
    "\n",
    "Hint: You can check the docstring by typing out the function name in a cell (`sns.pairplot(`)and hitting tab after within the parenthesis. \n",
    "OR by typing a question mark before the function name like `?sns.pairplot()` which will print out the full docstring. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pairplot, we see there does indeed seem to be some relationship between `life_expectancy`, and `income` and `children_per_woman` as we have seen before, but also with `sugar_intake_daiy`, and `bp_women`.\n",
    "\n",
    "It may be counter-intuitive that higher sugar intake (which is often associated with increased obesity, diabetes and other co-morbidities) would positively correlate with longer life expectancy. However, there could be an underlying variable, such as a country's overall wealth and welfare, which is the underlying driver for both the longer life expectancy and the higher sugar intake (such variables are said to be [\"confounding\"](https://en.wikipedia.org/wiki/Confounding).\n",
    "\n",
    "c. Using `plt.subplots()`, create a plot with **one row of two subplots** and set `figsize=(15,5)` to make plot sizes larger and easier to read: **(1 mark)**\n",
    "\n",
    "The first plot should be a scatterplot with `sugar_intake_daily` on the x-axis, and `income` on the `y-axis` while coloring the `hue` by `income_group`.\n",
    "\n",
    "The second plot should be a violinplot with `income_group` on the x-axis and `sugar_intake_daily` on the y-axis. Set the `order` parameter so that the income groups are shown in ascending order from left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: From Week 09, we learned to pass the correct axes variable to the seaborn plotting function (e.g. `ax=ax1`) to indicate where on the figure the plot should go. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we do see that there does seem to be a relationship between sugar intake and a nation's GDP, but there is a lot of variability within each group, suggesting income is not the only factor influencing sugar intake. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tests of association in our data (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to check for multicollinearity in our data. This is when two or more variables are highly correlated. We can do this using the built-in `corr()` function for dataframes in `pandas`. We set the correlation metric to `spearman` which can capture non-linear relationships, whereas the default metric, the `pearson` correlation is strictly for linear relationships.\n",
    "\n",
    "Run the code below to take a look **(you do not need to add any code here)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = world_data.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pairs `bp_women` and `bp_men`, and `years_in_school_men` and `years_in_school_women` are highly correlated which makes sense as they are the same indicators but in different genders. To avoid **multicollinearity**, we can either drop one (such as dropping the `bp_men` column), or combine these into a single value (such as creating a new column that has the gender ratio of years in school). \n",
    "\n",
    "___\n",
    "\n",
    "a. Create a new column in `world_data` called `education_gender_ratio` that divides `years_in_school_women` by `years_in_school_men`. **(0.5 marks)**\n",
    "\n",
    "b. Then, drop the three columns `bp_men`, `years_in_school_women` and `years_in_school_men` using the `drop()` function. Save the new dataframe in a variable called `new_world_data`. **(0.5 marks)**\n",
    "\n",
    "Here is an example of how to use it:\n",
    "\n",
    "`dataframe_2 = dataframe.drop(columns=[columnname1, columnname2, columname3])`. \n",
    "\n",
    "You can answer both (a) and (b) in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new column\n",
    "\n",
    "\n",
    "# drop the extra columns\n",
    "new_world_data = \n",
    "\n",
    "\n",
    "# keep this code here\n",
    "print(new_world_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You can create a new column based on other columns in a dataframe like this:\n",
    "\n",
    "`df['col3'] = df.col1 + df.col2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "We can create a model of our data using a linear regression and the factors that we think might be important. For example, we may be interested in whether how well parity between women's education and men's education may impact the health of a nation. \n",
    "\n",
    "c. Use `smf.ols()` (which uses formula notation) to create a model and fit it to model `life_expectancy` as a function of `education_gender_ratio`. You can append `.fit()` to the end of the model to fit it in the same line and get the results and store it in a variable called `results`. **(0.5 marks)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf # keep this line here\n",
    "\n",
    "results = smf.ols('life_expectancy ~ education_gender_ratio', new_world_data).fit()\n",
    "\n",
    "# keep this code here\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Formulas are strings that indicate the dependant and independant variable column names like:\n",
    "\n",
    "`dependant_y_value ~ independant_x_value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "We can plot our model's fit against the actual data. However, not all rows have an `education_ratio_gender` value. You can run `new_world_data.info()` for yourself to see that there are only 7636 non null values, out of a possible 11288 values. We need to make a clean subset of our data without any NA values, otherwise, there will be a descrepancy between the array of the predicted results, and values we do have in our actual data. \n",
    "\n",
    "We have created for you a new subset called `education_clean` from `new_world_data` using the `dataframe.dropna()` method. The argument `subset=['education_gender_ratio']` in `dropna()` is used to specifically drop rows only where the `education_gender_ratio` value is null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL AS IS\n",
    "education_clean = new_world_data.dropna(subset=['education_gender_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Using `education_clean`, create two scatterplots with `education_gender_ratio` on the x-axis, and `life_expectancy` on the y-axis. However, Oone should plot the *actual* life expectancy in `education_clean` and the second should use the values in `results.predict()`. **(0.5 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-processing our data ahead of any machine learning (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine whether we are able to predict a nation's life expectancy using other indicators, we are going to build a decision tree regressor using `scikit-learn`. The first step is to preprocess our data and get it in the right format for `scikit-learn`.\n",
    "\n",
    "We should think about which columns will contain information in our dataset. We can drop `country`, `sub_region` (which may be too specific for our model to find overarching patterns with limited data), and `income_group` (this information is available in a different form, represented in the `income` column).\n",
    "\n",
    "a. Create a new variable called `df` using `new_world_data` where we drop our unwanted columns using the `dataframe.drop()` and setting `columns=['country', 'sub_region', 'income_group']`. \n",
    "\n",
    "Then append `.dropna(how=any, axis=0)` to this line of code to clean our data and remove rows which have a null value in *any* of the columns. **(0.5 marks)**\n",
    "\n",
    "The structure will look something like: `dataframe.drop().dropna()` with the correct variable name and the necessary parameters filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \n",
    "\n",
    "# keep this code here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to create our X (features) and Y (target) variables that our model will train on. Our model will use the features in X to try to generate an accurate prediction of the target value in Y. \n",
    "\n",
    "b. Create a variable `Y` which only has the column `life_expectancy` from the `df` dataframe. **(0.25 marks)**\n",
    "\n",
    "c. Create a variable `X` which drops the `life_expectancy` column from the `df` dataframe (use the `columns=[columns...]` parameter). **(0.25 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = \n",
    "X = \n",
    "\n",
    "# Keep this code here\n",
    "# this performs the one-hot encoding of the categorical variables. \n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: When using the `columns=` parameter in `drop()`, the values need to be passed as a list `[ 'col' ]`, even if there is only one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, you will need to scale/normalize your data such that it is centered around 0 and unit invariant. The values in each column are scaled by the mean and standard deviation of the column. It is not uncommon for a machine learning algorithm to expect data to be centered around 0, and/or be approximately normally distributed. It is not as important for decision trees, but can still provide some benefits. \n",
    "\n",
    "c. Import `StandardScaler` from the `sklearn.preprocessing` module. Create an instance of the `StandardScaler()` called `scaler` and then on the next line, use `.fit()` to fit the `scaler` object on our feature data by passing `X` as an argument.(**0.5 marks)**\n",
    "\n",
    "Do not assign the fitted `scaler` to another variable, our `scaler` object will be updated automatically, in-place, by running `.fit()`. We can then use the updated `scaler` to apply the scaling transformation to the same feature set we fit the scaler on (we've done that for you in the last line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import class here\n",
    "\n",
    "\n",
    "# instantiate instance of StandardScaler, then fit the scaler\n",
    "scaler = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# keep this code here, this uses the fitted StandardScaler to transforms our data\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Split our features (`X_scaled`) and targets (`Y`) into a training set and a test set using `train_test_split`. **(0.5 marks)**\n",
    "- Set `test_size=0.2` (20% of our data is set aside for testing)\n",
    "- Set `random_state=0` so that the result is reproducible (there is some randomness involved in these models). \n",
    "- the output is four different arrays in the following order:\n",
    "    1. X_train (the feature training set)\n",
    "    2. X_test (the feature test set)\n",
    "    3. Y_train (the target training set)\n",
    "    4. Y_test (the target test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # keep this here\n",
    "\n",
    "..., ..., ..., ... = ...\n",
    "\n",
    "\n",
    "# keep this code here\n",
    "# confirm the size of the train set and test set make sense\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and evaluating a decision tree regressor (2 marks)\n",
    "Now that we have prepared our data, we can instantiate and train our model. \n",
    "\n",
    "The typical `scikit-learn` workflow is:\n",
    "1. Define an instance of the model of choice, for example, `model = LinearRegression(random_state=0)`\n",
    "2. Fit `model` on our training features and target data like `model.fit(X_train, Y_train)`\n",
    "3. Use the fitted model to make predictions on our test feature set like `preds = model.predict(X_test)`\n",
    "4. Score the performance of our model's predictions against the known target values like `model.score(X_test, Y_test)`  which is built into the model and scores the correlation, \n",
    "5. OR use our own function to score the difference between predictions and targets like `custom_scoring_function(preds, Y_test)`\n",
    "___\n",
    "\n",
    "a. Instantiate a `DecisionTreeRegressor` called `tree_model` with a `random_state=0`. **(0.5 marks)**   \n",
    "b. Fit `tree_model` on the training data (features and targets). **(0.5 marks)**  \n",
    "c. Use the fitted `tree_model` to predict the `life_expectancy` based on the features in the test set (`X_test`) and store in `Y_pred`. **(0.5 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor # keep this code here\n",
    "\n",
    "# create an instance of the Decision Tree Regressor\n",
    "tree_model = \n",
    "\n",
    "# fit the model\n",
    "\n",
    "\n",
    "# predictions\n",
    "\n",
    "\n",
    "# keep this code here\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. To see how well our model performed, use the `DecisionTreeRegressor`'s built-in `score()` function to see the correlation between the actual and predicted life expectancy values. **(0.25 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tree = \n",
    "\n",
    "# keep this code here\n",
    "print(corr_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Plot a scatterplot using the `tree_model` predicted `life_expectancy` values we already stored in `Y_pred` for the x-axis, versus the actual values in `Y_test` on the y-axis. **(0.25 marks)**\n",
    "\n",
    "This plot shows for which values your model performed well (assembling in a straight line) and for which there might be other factors influencing the outcome (far from the straight line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you're done! The next bit is just for educational purposes. Read on to see the **feature importances** for our model. \n",
    "___\n",
    "If we wanted to learn more about how our model works, decision trees have a nice function that allows us to see the feature importances, telling us which features were most informative in deriving the predicted value. \n",
    "\n",
    "Run the next cell to see the relative importance of each feature for the decision tree regressor. Do they make sense based on what we've already observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = tree_model.feature_importances_.argsort() # argsort() sorts the values from lowest to highest and returns the indices\n",
    "\n",
    "# we can use those sorted_indices to reorder our columns and tell us which columns were most important\n",
    "# the [::-1] reverses the order so it goes high to low instead\n",
    "X.columns[sorted_indices][::-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also remember from lecture that decision trees are non-parametric models, meaning they do not require our data to be scaled (but it was good to practice using these functions!). Run the following to see if there was any difference between using our scaled or non-scaled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0) # use X instead of X_scaled\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=0)\n",
    "tree_model.fit(X_train, Y_train)\n",
    "Y_pred = tree_model.predict(X_test)\n",
    "print(\"Non-scaled accuracy:\", tree_model.score(X_test, Y_test))\n",
    "print(\"Scaled accuracy:\", corr_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
